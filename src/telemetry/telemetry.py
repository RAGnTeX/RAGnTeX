"""Telemetry utilities for Langfuse integration and OpenTelemetry tracing."""

import os
import hashlib
from typing import Union
from contextlib import contextmanager

# import psycopg2
import base64
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter

from .logging_utils import Logger

LOGGER = Logger.get_logger()

tracer = None


def init_telemetry() -> None:
    """Setup langfuse, initialize OpenTelemetry for tracing."""
    if os.getenv("USE_LANGFUSE", "false").lower() == "true":
        os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
            os.environ["LANGFUSE_HOST"] + "/api/public/otel"
        )
        auth = f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}"
        auth_b64 = base64.b64encode(auth.encode()).decode()
        os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {auth_b64}"

        provider = TracerProvider()
        exporter = OTLPSpanExporter()
        provider.add_span_processor(SimpleSpanProcessor(exporter))
        trace.set_tracer_provider(provider)

        global tracer
        tracer = trace.get_tracer("langfuse.genai")

    else:
        LOGGER.warning("Langfuse telemetry is disabled (USE_LANGFUSE != true)")


def hash_prompt(text: str) -> str:
    """Generate a SHA-256 hash of the prompt.
    Args:
        text (str): The input text to hash."""
    return hashlib.sha256(text.encode()).hexdigest()


@contextmanager
def traced_block(name: str, **attrs):
    """Context manager to create a traced block.
    Args:
        name (str): The name of the span.
        **attrs: Additional attributes to set on the span."""
    with tracer.start_as_current_span(name) as span:
        for key, value in attrs.items():
            span.set_attribute(key, value)
        try:
            yield span  # Control to the block
        except Exception as e:
            # Record exception and mark span status as error
            span.record_exception(e)
            span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))
            LOGGER.error("Error in span %s while generating content: %s", name, e)
            raise


def generate_with_trace(client, model_name: str, prompt: str) -> Union[object, None]:
    """Save traces from the generation.
    Args:
        client: google genai client instance.
        model_name (str): The name of the model to use.
        prompt (str): The input prompt for generation."""
    with tracer.start_as_current_span("ðŸ¤– genai_generate") as span:
        span.set_attribute("input.prompt_hash", hash_prompt(prompt))
        span.set_attribute("input.prompt_length", len(prompt))
        span.set_attribute("input.model_name", model_name)
        try:
            response = client.models.generate_content(model=model_name, contents=prompt)
            span.set_attribute("output.response_length", len(str(response)))
            span.set_attribute("output.success", True)
            return response
        except Exception as e:
            span.set_attribute("output.success", False)
            span.record_exception(e)
            span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))
            return LOGGER.error("Error in spans while generating content: %s", e)
